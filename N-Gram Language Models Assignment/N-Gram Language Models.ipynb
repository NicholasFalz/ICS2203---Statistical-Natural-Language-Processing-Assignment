{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f23921a1",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b5e2b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import sys\n",
    "import math\n",
    "import string\n",
    "import xml.etree.ElementTree as ET\n",
    "import random\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c4093f",
   "metadata": {},
   "source": [
    "### Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8af80066",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files = [\"A6U.xml\", \"F98.xml\", \"J18.xml\", \"B17.xml\", \"EW1.xml\", \"FSS.xml\", \"CLW.xml\",\n",
    "              \"KBC.xml\", \"KD7.xml\", \"KSN.xml\", \"KCU.xml\", \"KE4.xml\", \"KP2.xml\", \"KCV.xml\",\n",
    "              \"AC2.xml\", \"BMW.xml\", \"G0L.xml\", \"H9C.xml\", \"GUU.xml\", \"CCW.xml\",\n",
    "              \"A1H.xml\", \"A1P.xml\", \"A3K.xml\", \"A8N.xml\", \"A9X.xml\", \"A2D.xml\", \"A82.xml\", \"AAR.xml\", \"AA3.xml\", \"AJF.xml\", \"CBD.xml\", \"K2C.xml\", \"K3A.xml\", \"K58.xml\", \"K4U.xml\", \"K29.xml\", \"A8T.xml\", \"AHH.xml\", \"CBM.xml\", \"A7T.xml\", \"AL0.xml\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc4ad100",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_corpus = []\n",
    "test_corpus = []\n",
    "\n",
    "def extract_corpus():\n",
    "    test_data = []\n",
    "    training_data = []\n",
    "\n",
    "    texts_directory = \"download/Texts\"\n",
    "\n",
    "    for genre in os.listdir(texts_directory):\n",
    "        if not genre.startswith('.'): # ignores mac hidden file\n",
    "            for file in os.listdir(os.path.join(texts_directory, genre)):\n",
    "                if file in test_files:\n",
    "                    test_data.append(ET.parse(os.path.join(texts_directory, genre, file)))\n",
    "                else:\n",
    "                    training_data.append(ET.parse(os.path.join(texts_directory, genre, file)))\n",
    "    \n",
    "    # Extracting training data:\n",
    "    for file in training_data:\n",
    "        for tree in file.getroot():\n",
    "            for sentence in tree.iter('s'):\n",
    "                sen = ['<s>']\n",
    "                for word in sentence:\n",
    "                    if word.text is not None and word.text not in string.punctuation: \n",
    "                        if word.text[-1] == ' ':\n",
    "                            sen.append(word.text[:-1].lower()) # removes the space found at the end of most words in the british corpus\n",
    "                        else:\n",
    "                            sen.append(word.text.lower())\n",
    "                sen.append('</s>')\n",
    "\n",
    "                training_corpus.append(sen)\n",
    "                \n",
    "    # Extracting test data:\n",
    "    for file in test_data:\n",
    "        for tree in file.getroot():\n",
    "            for sentence in tree.iter('s'):\n",
    "                sen = ['<s>']\n",
    "                for word in sentence:\n",
    "                    if word.text is not None and word.text not in string.punctuation: \n",
    "                        if word.text[-1] == ' ':\n",
    "                            sen.append(word.text[:-1].lower())\n",
    "                        else:\n",
    "                            sen.append(word.text.lower())\n",
    "                sen.append('</s>')\n",
    "\n",
    "                test_corpus.append(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1792035",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_training = []\n",
    "words_test = []\n",
    "\n",
    "def calculate_corpus_stats():\n",
    "    for sentence in training_corpus:\n",
    "        for word in sentence:\n",
    "            words_training.append(word)\n",
    "\n",
    "    for sentence in test_corpus:\n",
    "        for word in sentence:\n",
    "            words_test.append(word)\n",
    "\n",
    "    vocab_training = set(words_training)\n",
    "    vocab_test = set(words_test)\n",
    "\n",
    "    words_total = len(words_training) + len(words_test)\n",
    "    \n",
    "    #print(\"Total number of words in the training corpus: \" + str(len(words_training)))\n",
    "    #print(\"Unique number of words in the training corpus: \" + str(len(vocab_training)))\n",
    "    #print(\"\")\n",
    "    #print(\"Total number of words in the test corpus: \" + str(len(words_test)))\n",
    "    #print(\"Unique number of words in the test corpus: \" + str(len(vocab_test)))\n",
    "    #print(\"\")\n",
    "    #print(\"Test corpus %: \" + str(len(words_test) / (words_total) * 100))\n",
    "    #print(\"Training corpus %: \" + str(len(words_training) / (words_total) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d47d703",
   "metadata": {},
   "source": [
    "### Calculating Frequency Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20a69a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_counts = {}\n",
    "bigram_counts = {}\n",
    "trigram_counts = {}\n",
    "\n",
    "def frequency_counter(corpus):\n",
    "    for sentence in corpus:\n",
    "        for i in range(len(sentence)):\n",
    "            unigram = sentence[i]\n",
    "\n",
    "            if unigram in unigram_counts.keys():\n",
    "                unigram_counts[unigram] += 1\n",
    "            else:\n",
    "                unigram_counts[unigram] = 1\n",
    "            \n",
    "    for sentence in corpus:\n",
    "        for i in range(len(sentence) - 1):\n",
    "            bigram = (sentence[i], sentence[i+1])\n",
    "\n",
    "            if bigram in bigram_counts.keys():\n",
    "                bigram_counts[bigram] += 1\n",
    "            else:\n",
    "                bigram_counts[bigram] = 1\n",
    "                \n",
    "    for sentence in corpus:\n",
    "        for i in range(len(sentence) - 2):\n",
    "            trigram = (sentence[i], sentence[i+1], sentence[i+2])\n",
    "\n",
    "            if trigram in trigram_counts.keys():\n",
    "                trigram_counts[trigram] += 1\n",
    "            else:\n",
    "                trigram_counts[trigram] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfd4b41",
   "metadata": {},
   "source": [
    "### Vanilla Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24dd9fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "P_vanilla_unigram = {}\n",
    "P_vanilla_bigram = {}\n",
    "P_vanilla_trigram = {}\n",
    "\n",
    "def calculate_vanilla():\n",
    "    for unigram in unigram_counts:\n",
    "        P_vanilla_unigram[unigram] = unigram_counts[unigram] / len(words_training)\n",
    "        \n",
    "    for bigram in bigram_counts:\n",
    "        P_vanilla_bigram[bigram] = bigram_counts[bigram] / unigram_counts[bigram[0]]\n",
    "    \n",
    "    for trigram in trigram_counts:\n",
    "        P_vanilla_trigram[trigram] = trigram_counts[trigram] / bigram_counts[trigram[0:2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd649c8",
   "metadata": {},
   "source": [
    "### Laplace Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77298ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "P_laplace_unigram = {}\n",
    "P_laplace_bigram = {}\n",
    "P_laplace_trigram = {}\n",
    "l = len(set(words_training))\n",
    "\n",
    "def calculate_laplace():\n",
    "    for unigram in unigram_counts:\n",
    "        P_laplace_unigram[unigram] = (unigram_counts[unigram] + 1) / (len(words_training) + l)\n",
    "\n",
    "    for bigram in bigram_counts:\n",
    "        P_laplace_bigram[bigram] = (bigram_counts[bigram] + 1) / (unigram_counts[bigram[0]] + l)\n",
    "\n",
    "    for trigram in trigram_counts:\n",
    "        P_laplace_trigram[trigram] = (trigram_counts[trigram] + 1) / (bigram_counts[trigram[0:2]] + l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7342bec7",
   "metadata": {},
   "source": [
    "### UNK Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abf63060",
   "metadata": {},
   "outputs": [],
   "source": [
    "P_unk_unigram = {}\n",
    "P_unk_bigram = {}\n",
    "P_unk_trigram = {}\n",
    "\n",
    "def calculate_unk():\n",
    "    # Creating a list of all unknown words in the corpus (less than 2 frequency):\n",
    "    unk_list = []\n",
    "\n",
    "    for unigram in unigram_counts:\n",
    "        if unigram_counts[unigram] <= 2:\n",
    "            unk_list.append(unigram)\n",
    "        \n",
    "    unk_set = set(unk_list) # converting to set for faster memberhsip checking\n",
    "        \n",
    "    # Replacing all words in the training corpus with frequency less than 2 with <UNK> tag:\n",
    "    for i, sentence in enumerate(training_corpus):\n",
    "        for j, word in enumerate(sentence):\n",
    "            if word in unk_set:\n",
    "                training_corpus[i][j] = \"<UNK>\"\n",
    "            \n",
    "    frequency_counter(training_corpus)\n",
    "    \n",
    "    for unigram in unigram_counts:\n",
    "        P_unk_unigram[unigram] = unigram_counts[unigram] / len(words_training)\n",
    "        \n",
    "    for bigram in bigram_counts:\n",
    "        P_unk_bigram[bigram] = bigram_counts[bigram] / unigram_counts[bigram[0]]\n",
    "    \n",
    "    for trigram in trigram_counts:\n",
    "        P_unk_trigram[trigram] = trigram_counts[trigram] / bigram_counts[trigram[0:2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d45261",
   "metadata": {},
   "source": [
    "### Sen_Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0dd63155",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sen_probability(sentence, language_model, n_gram):\n",
    "    P_unigram = 1\n",
    "    P_bigram = 1\n",
    "    P_trigram = 1\n",
    "    \n",
    "    if language_model == \"vanilla\":\n",
    "        if n_gram == \"unigram\":\n",
    "            for i in range(len(sentence)):\n",
    "                if sentence[i] in P_vanilla_unigram.keys():\n",
    "                    P_unigram *= P_vanilla_unigram[sentence[i]]\n",
    "                else: P_unigram *= 0\n",
    "            return P_unigram\n",
    "        elif n_gram == \"bigram\":\n",
    "            for i in range(len(sentence) - 1):\n",
    "                sequence = (sentence[i], sentence[i+1])\n",
    "                if sequence in P_vanilla_bigram.keys():\n",
    "                    P_bigram *= P_vanilla_bigram[sequence]\n",
    "                else: P_bigram *= 0\n",
    "            return P_bigram\n",
    "        elif n_gram == \"trigram\":\n",
    "            for i in range(len(sentence) - 2):\n",
    "                sequence = (sentence[i], sentence[i+1], sentence[i+2])\n",
    "                if sequence in P_vanilla_trigram.keys():\n",
    "                    P_trigram *= P_vanilla_trigram[sequence]\n",
    "                else: P_trigram *= 0\n",
    "            return P_trigram\n",
    "        else: print(\"Invalid n-gram input\")\n",
    "            \n",
    "    elif language_model == \"laplace\":\n",
    "        if n_gram == \"unigram\":\n",
    "            for i in range(len(sentence)):\n",
    "                if sentence[i] in P_laplace_unigram.keys():\n",
    "                    P_unigram *= P_laplace_unigram[sentence[i]]\n",
    "                else: P_unigram *= 0\n",
    "            return P_unigram\n",
    "        elif n_gram == \"bigram\":\n",
    "            for i in range(len(sentence) - 1):\n",
    "                sequence = (sentence[i], sentence[i+1])\n",
    "                if sequence in P_laplace_bigram.keys():\n",
    "                    P_bigram *= P_laplace_bigram[sequence]\n",
    "                else: P_bigram *= 0\n",
    "            return P_bigram\n",
    "        elif n_gram == \"trigram\":\n",
    "            for i in range(len(sentence) - 2):\n",
    "                sequence = (sentence[i], sentence[i+1], sentence[i+2])\n",
    "                if sequence in P_laplace_trigram.keys():\n",
    "                    P_trigram *= P_laplace_trigram[sequence]\n",
    "                else: P_trigram *= 0\n",
    "            return P_trigram\n",
    "        else: print(\"Invalid n-gram input\")\n",
    "            \n",
    "    elif language_model == \"unk\":\n",
    "        if n_gram == \"unigram\":\n",
    "            for i in range(len(sentence)):\n",
    "                if sentence[i] in P_unk_unigram.keys():\n",
    "                    P_unigram *= P_unk_unigram[sentence[i]]\n",
    "                else: P_unigram *= 0\n",
    "            return P_unigram\n",
    "        elif n_gram == \"bigram\":\n",
    "            for i in range(len(sentence) - 1):\n",
    "                sequence = (sentence[i], sentence[i+1])\n",
    "                if sequence in P_unk_bigram.keys():\n",
    "                    P_bigram *= P_unk_bigram[sequence]\n",
    "                else: P_bigram *= 0\n",
    "            return P_bigram\n",
    "        elif n_gram == \"trigram\":\n",
    "            for i in range(len(sentence) - 2):\n",
    "                sequence = (sentence[i], sentence[i+1], sentence[i+2])\n",
    "                if sequence in P_unk_trigram.keys():\n",
    "                    P_trigram *= P_unk_trigram[sequence]\n",
    "                else: P_trigram *= 0\n",
    "            return P_trigram\n",
    "        else: print(\"Invalid n-gram input\")\n",
    "            \n",
    "    else: print(\"Invalid languge model input\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb227e2d",
   "metadata": {},
   "source": [
    "### Linear Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9817ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_interpolation(language_model, sentence):\n",
    "    trigram_lambda = 0.6\n",
    "    bigram_lambda = 0.3\n",
    "    unigram_lambda = 0.1\n",
    "    \n",
    "    sentence_probabilities = {}\n",
    "    \n",
    "    if language_model == \"vanilla\":\n",
    "        sentence_probabilities[\"unigram\"] = sen_probability(sentence, \"vanilla\", \"unigram\")\n",
    "        sentence_probabilities[\"bigram\"] = sen_probability(sentence, \"vanilla\", \"bigram\")\n",
    "        sentence_probabilities[\"trigram\"] = sen_probability(sentence, \"vanilla\", \"trigram\")\n",
    "        \n",
    "    elif language_model == \"laplace\":\n",
    "        sentence_probabilities[\"unigram\"] = sen_probability(sentence, \"laplace\", \"unigram\")\n",
    "        sentence_probabilities[\"bigram\"] = sen_probability(sentence, \"laplace\", \"bigram\")\n",
    "        sentence_probabilities[\"trigram\"] = sen_probability(sentence, \"laplace\", \"trigram\")\n",
    "        \n",
    "    elif language_model == \"unk\":\n",
    "        sentence_probabilities[\"unigram\"] = sen_probability(sentence, \"unk\", \"unigram\")\n",
    "        sentence_probabilities[\"bigram\"] = sen_probability(sentence, \"unk\", \"bigram\")\n",
    "        sentence_probabilities[\"trigram\"] = sen_probability(sentence, \"unk\", \"trigram\")\n",
    "        \n",
    "    else: print(\"Invalid language model Input\")\n",
    "\n",
    "    P_interpolated = (unigram_lambda * sentence_probabilities[\"unigram\"]) + (bigram_lambda * sentence_probabilities[\"bigram\"]) + (trigram_lambda * sentence_probabilities[\"trigram\"]) \n",
    "\n",
    "    return P_interpolated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0517a0c1",
   "metadata": {},
   "source": [
    "### Perplexity Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36042ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_perplexity_table(corpus):\n",
    "    language_models = [\"vanilla\", \"laplace\", \"unk\"]\n",
    "    ngrams = [\"unigram\", \"bigram\", \"trigram\", \"linear-interpolation\"]\n",
    "    pp = {}\n",
    "    \n",
    "    for language_model in language_models:\n",
    "        for ngram in ngrams:\n",
    "            probabilities = []\n",
    "            count = 0\n",
    "            key = (language_model, ngram)\n",
    "            if ngram != \"linear-interpolation\":\n",
    "                for sentence in corpus:\n",
    "                    p = sen_probability(sentence, language_model, ngram)\n",
    "                    if p != 0:\n",
    "                        probabilities.append(p)\n",
    "                        count += len(sentence)\n",
    "            else:\n",
    "                for sentence in corpus:\n",
    "                    p = linear_interpolation(language_model, sentence)\n",
    "                    if p != 0:\n",
    "                        probabilities.append(p)\n",
    "                        count += len(sentence)\n",
    "    \n",
    "            pp[key] = pow(2, -sum(math.log2(p) for p in probabilities) / count)\n",
    "        \n",
    "    data = [[\"       \", \"Unigram\",                   \"Bigram\",                    \"Trigram\",                 \"Linear Interpolation\"],\n",
    "            [\"Vanilla\", pp[(\"vanilla\", \"unigram\")],  pp[(\"vanilla\", \"bigram\")],   pp[\"vanilla\", \"trigram\"],  pp[\"vanilla\", \"linear-interpolation\"]],\n",
    "            [\"Laplace\", pp[(\"laplace\", \"unigram\")],  pp[\"laplace\", \"bigram\"],     pp[\"laplace\", \"trigram\"],  pp[\"laplace\", \"linear-interpolation\"]],\n",
    "            [\"UNK\",     pp[\"unk\", \"unigram\"],        pp[(\"unk\", \"bigram\")],       pp[\"unk\", \"trigram\"],      pp[\"unk\", \"linear-interpolation\"]]]\n",
    "    \n",
    "    print(tabulate(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c9fb44",
   "metadata": {},
   "source": [
    "### Generate Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c2d84fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence():\n",
    "    while True:\n",
    "        language_model = input(\"Select a Language Model:\\nVanilla\\nLaplace\\nUNK\\n\")\n",
    "        language_model = language_model.lower()\n",
    "            \n",
    "        if language_model == \"vanilla\" or language_model == \"laplace\" or language_model == \"unk\":\n",
    "            break\n",
    "        else:\n",
    "            print(\"Invalid Input\")\n",
    "    \n",
    "    print(\"Input a phrase\")\n",
    "    phrase = input()\n",
    "    print(\"\")\n",
    "    \n",
    "    new_sentence = phrase.split()\n",
    "    new_sentence.insert(0, \"<s>\")\n",
    "    \n",
    "    new_sentence = [x.lower() for x in new_sentence]\n",
    "    \n",
    "    next_word = \"\"\n",
    "    \n",
    "    print(phrase, end = ' ')\n",
    "    \n",
    "    while next_word != \"</s>\":\n",
    "        possible_words = []\n",
    "        probabilities = []\n",
    "        \n",
    "        context = tuple(new_sentence[-2:])\n",
    "\n",
    "        if language_model == \"vanilla\":\n",
    "            for key in P_vanilla_trigram.keys():\n",
    "                if key[0:2] == context:\n",
    "                    possible_words.append(key)\n",
    "                    probabilities.append(P_vanilla_trigram[key])\n",
    "        elif language_model == \"laplace\":\n",
    "            for key in P_laplace_trigram.keys():\n",
    "                if key[0:2] == context:\n",
    "                    possible_words.append(key)\n",
    "                    probabilities.append(P_laplace_trigram[key])\n",
    "        elif language_model == \"unk\":\n",
    "             for key in P_unk_trigram.keys():\n",
    "                if key[0:2] == context:\n",
    "                    possible_words.append(key)\n",
    "                    probabilities.append(P_unk_trigram[key])\n",
    "                    \n",
    "        choice = random.choices(possible_words, weights = probabilities, k=1)\n",
    "\n",
    "        next_word = choice[0][2]\n",
    "        \n",
    "        new_sentence.append(next_word)\n",
    "        \n",
    "        if next_word == '</s>':\n",
    "            print(\".\", end = ' ')\n",
    "        elif next_word == 'i':\n",
    "            print(next_word.capitalize(), end = ' ')\n",
    "        else: print(next_word, end = ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a877873b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.957848072052002 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "extract_corpus()\n",
    "calculate_corpus_stats()\n",
    "frequency_counter(training_corpus)\n",
    "calculate_vanilla()\n",
    "calculate_laplace()\n",
    "calculate_unk()\n",
    "\n",
    "end = time.time()\n",
    "print(str(end-start) + \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c720daa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------  -----------------  ------------------  ------------------  --------------------\n",
      "         Unigram            Bigram              Trigram             Linear Interpolation\n",
      "Vanilla  519.5210327818343  30.623874930158117  3.911211062659215   305.1950335793441\n",
      "Laplace  513.5022334049727  29.4037458259578    3.6844946467983966  296.6078563146629\n",
      "UNK      261.6247518922054  30.62828139570548   3.9116638189738113  186.2329985227002\n",
      "-------  -----------------  ------------------  ------------------  --------------------\n"
     ]
    }
   ],
   "source": [
    "calculate_perplexity_table(test_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db3457b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select a Language Model:\n",
      "Vanilla\n",
      "Laplace\n",
      "UNK\n",
      "vanilla\n",
      "Input a phrase\n",
      "every time\n",
      "\n",
      "every time he had an audience shuffling , coughing in the public â€™ and to the loose ball and conceded a penalty decision . "
     ]
    }
   ],
   "source": [
    "generate_sentence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dfb1b61d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory required for Vanilla Language Model Dictionary: 128450840 bytes\n",
      "Memory required for Laplace Language Model Dictionary: 128450840 bytes\n",
      "Memory required for UNK Language Model Dictionary: 128450840 bytes\n"
     ]
    }
   ],
   "source": [
    "memory_vanilla = sys.getsizeof(P_vanilla_unigram) + sys.getsizeof(P_vanilla_bigram) + sys.getsizeof(P_vanilla_trigram)\n",
    "memory_laplace = sys.getsizeof(P_laplace_unigram) + sys.getsizeof(P_laplace_bigram) + sys.getsizeof(P_laplace_trigram)\n",
    "memory_unk = sys.getsizeof(P_unk_unigram) + sys.getsizeof(P_unk_bigram) + sys.getsizeof(P_unk_trigram)\n",
    "\n",
    "print(\"Memory required for Vanilla Language Model Dictionary: \" + str(memory_vanilla) + \" bytes\")\n",
    "print(\"Memory required for Laplace Language Model Dictionary: \" + str(memory_laplace) + \" bytes\")\n",
    "print(\"Memory required for UNK Language Model Dictionary: \" + str(memory_unk) + \" bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d218df4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>', 'it', 'was', 'a', 'nice', 'day', '</s>']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"It was a nice day\"\n",
    "\n",
    "sentence = sentence.split()\n",
    "sentence = [x.lower() for x in sentence]\n",
    "sentence.insert(0, \"<s>\")\n",
    "sentence.append(\"</s>\")\n",
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "11ee3764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vanilla: 1.5871509696627568e-09\n",
      "Laplace: 1.7437044228039855e-09\n",
      "UNK: 1.5871509696627568e-09\n"
     ]
    }
   ],
   "source": [
    "print(\"Vanilla: \" + str(sen_probability(sentence, \"vanilla\", \"bigram\")))\n",
    "print(\"Laplace: \" + str(sen_probability(sentence, \"laplace\", \"bigram\")))\n",
    "print(\"UNK: \" + str(sen_probability(sentence, \"unk\", \"bigram\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48590662",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
